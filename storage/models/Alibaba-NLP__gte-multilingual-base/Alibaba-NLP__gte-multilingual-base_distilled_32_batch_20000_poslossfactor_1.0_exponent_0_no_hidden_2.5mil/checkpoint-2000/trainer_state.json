{
  "best_global_step": 2000,
  "best_metric": 0.01404985599219799,
  "best_model_checkpoint": "/home/kotsios/dsit/thesis/thesis_project/storage/models/Alibaba-NLP__gte-multilingual-base/Alibaba-NLP__gte-multilingual-base_distilled_32_batch_20000_poslossfactor_1.0/checkpoint-2000",
  "epoch": 16.0,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.0,
      "grad_norm": 0.016397247090935707,
      "learning_rate": 0.002202486678507993,
      "loss": 0.4276,
      "step": 125
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.09155431389808655,
      "step": 125
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.003186875721439719,
      "learning_rate": 0.004422735346358792,
      "loss": 0.0294,
      "step": 250
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0387907475233078,
      "step": 250
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.001512198243290186,
      "learning_rate": 0.006642984014209592,
      "loss": 0.0148,
      "step": 375
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.02293819934129715,
      "step": 375
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.001006461912766099,
      "learning_rate": 0.008863232682060391,
      "loss": 0.0105,
      "step": 500
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.017273157835006714,
      "step": 500
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.0007733447127975523,
      "learning_rate": 0.009535060975609756,
      "loss": 0.0091,
      "step": 625
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.015755122527480125,
      "step": 625
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.0006712675094604492,
      "learning_rate": 0.008582317073170732,
      "loss": 0.0086,
      "step": 750
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.01519019715487957,
      "step": 750
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.0006371137569658458,
      "learning_rate": 0.007629573170731707,
      "loss": 0.0084,
      "step": 875
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.014841671101748943,
      "step": 875
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.0007182362023741007,
      "learning_rate": 0.006676829268292684,
      "loss": 0.0083,
      "step": 1000
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.014671850949525833,
      "step": 1000
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.0006592608406208456,
      "learning_rate": 0.005724085365853658,
      "loss": 0.0082,
      "step": 1125
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.014423674903810024,
      "step": 1125
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.0006343852146528661,
      "learning_rate": 0.004771341463414634,
      "loss": 0.0081,
      "step": 1250
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.014368027448654175,
      "step": 1250
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.0006456822738982737,
      "learning_rate": 0.0038185975609756097,
      "loss": 0.0081,
      "step": 1375
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.014303959906101227,
      "step": 1375
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.0007605116697959602,
      "learning_rate": 0.0028658536585365853,
      "loss": 0.008,
      "step": 1500
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.014223088510334492,
      "step": 1500
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.000661571160890162,
      "learning_rate": 0.0019131097560975612,
      "loss": 0.008,
      "step": 1625
    },
    {
      "epoch": 13.0,
      "eval_loss": 0.014179776422679424,
      "step": 1625
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.0005572112859226763,
      "learning_rate": 0.0009603658536585367,
      "loss": 0.008,
      "step": 1750
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.014168239198625088,
      "step": 1750
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.0005788295529782772,
      "learning_rate": 7.621951219512196e-06,
      "loss": 0.008,
      "step": 1875
    },
    {
      "epoch": 15.0,
      "eval_loss": 0.014132128097116947,
      "step": 1875
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.0005929914768785238,
      "learning_rate": 0.002862857142857143,
      "loss": 0.0079,
      "step": 2000
    },
    {
      "epoch": 16.0,
      "eval_loss": 0.01404985599219799,
      "step": 2000
    }
  ],
  "logging_steps": 500,
  "max_steps": 2500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 1,
        "early_stopping_threshold": 0.005
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": true,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 20000,
  "trial_name": null,
  "trial_params": null
}
