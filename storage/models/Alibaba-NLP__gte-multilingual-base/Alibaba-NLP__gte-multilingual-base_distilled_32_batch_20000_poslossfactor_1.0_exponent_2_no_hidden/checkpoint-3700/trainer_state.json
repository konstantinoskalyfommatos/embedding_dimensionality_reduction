{
  "best_global_step": 3700,
  "best_metric": 0.01245383732020855,
  "best_model_checkpoint": "/home/kotsios/dsit/thesis/thesis_project/storage/models/Alibaba-NLP__gte-multilingual-base/Alibaba-NLP__gte-multilingual-base_distilled_32_batch_20000_poslossfactor_1.0_exponent_2_no_hidden/checkpoint-3700",
  "epoch": 7.4,
  "eval_steps": 100,
  "global_step": 3700,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2,
      "grad_norm": 0.023443063721060753,
      "learning_rate": 0.00198,
      "loss": 0.4728,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.10698942095041275,
      "step": 100
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.004396968521177769,
      "learning_rate": 0.00398,
      "loss": 0.0363,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.0447879396378994,
      "step": 200
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.00199686735868454,
      "learning_rate": 0.00598,
      "loss": 0.017,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 0.027302078902721405,
      "step": 300
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.0012852591462433338,
      "learning_rate": 0.007980000000000001,
      "loss": 0.0117,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.019308120012283325,
      "step": 400
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.0008333316072821617,
      "learning_rate": 0.009980000000000001,
      "loss": 0.0094,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.016159091144800186,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.016159091144800186,
      "step": 500
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.0006966798682697117,
      "learning_rate": 0.00978,
      "loss": 0.0085,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 0.015107613056898117,
      "step": 600
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.0007376514258794487,
      "learning_rate": 0.009557777777777778,
      "loss": 0.0081,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 0.014617349952459335,
      "step": 700
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.0007479970809072256,
      "learning_rate": 0.009335555555555555,
      "loss": 0.008,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 0.014424340799450874,
      "step": 800
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.0007228728500194848,
      "learning_rate": 0.009113333333333333,
      "loss": 0.0078,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 0.014131435193121433,
      "step": 900
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.0005828496068716049,
      "learning_rate": 0.008891111111111112,
      "loss": 0.0077,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.013960675336420536,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.013960675336420536,
      "step": 1000
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.0005510248593054712,
      "learning_rate": 0.00866888888888889,
      "loss": 0.0077,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 0.01382172480225563,
      "step": 1100
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.0005872867186553776,
      "learning_rate": 0.008446666666666667,
      "loss": 0.0076,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 0.013633189722895622,
      "step": 1200
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.0005712076090276241,
      "learning_rate": 0.008224444444444444,
      "loss": 0.0075,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 0.013512080535292625,
      "step": 1300
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.0005394498584792018,
      "learning_rate": 0.008002222222222221,
      "loss": 0.0075,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 0.013498997315764427,
      "step": 1400
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.0005906414007768035,
      "learning_rate": 0.0077800000000000005,
      "loss": 0.0074,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.01342935673892498,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.01342935673892498,
      "step": 1500
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.0005397609784267843,
      "learning_rate": 0.007557777777777778,
      "loss": 0.0074,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 0.01327796932309866,
      "step": 1600
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.0005218936130404472,
      "learning_rate": 0.007335555555555555,
      "loss": 0.0074,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 0.013181363232433796,
      "step": 1700
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.0005473729688674212,
      "learning_rate": 0.0071133333333333335,
      "loss": 0.0073,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 0.01314530335366726,
      "step": 1800
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.0008102769497781992,
      "learning_rate": 0.006891111111111112,
      "loss": 0.0073,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 0.013173218816518784,
      "step": 1900
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.0007279111887328327,
      "learning_rate": 0.006668888888888889,
      "loss": 0.0073,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.012994133867323399,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.012994133867323399,
      "step": 2000
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.000534017919562757,
      "learning_rate": 0.006446666666666667,
      "loss": 0.0073,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 0.012989589013159275,
      "step": 2100
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.0005135356914252043,
      "learning_rate": 0.006224444444444445,
      "loss": 0.0072,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 0.012944227084517479,
      "step": 2200
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.0005362830706872046,
      "learning_rate": 0.006002222222222222,
      "loss": 0.0072,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 0.012808752246201038,
      "step": 2300
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.0005770330899395049,
      "learning_rate": 0.0057799999999999995,
      "loss": 0.0072,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 0.012814175337553024,
      "step": 2400
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.0005838879151269794,
      "learning_rate": 0.005557777777777779,
      "loss": 0.0072,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.012802612036466599,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.012802612036466599,
      "step": 2500
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.0005393643514253199,
      "learning_rate": 0.005335555555555556,
      "loss": 0.0072,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 0.012795839458703995,
      "step": 2600
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.0005084034637548029,
      "learning_rate": 0.0051133333333333334,
      "loss": 0.0072,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 0.012749020010232925,
      "step": 2700
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.0005182981840334833,
      "learning_rate": 0.004891111111111111,
      "loss": 0.0072,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 0.01276322454214096,
      "step": 2800
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.0005947814788669348,
      "learning_rate": 0.004668888888888889,
      "loss": 0.0071,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 0.012699637562036514,
      "step": 2900
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.0006978894234634936,
      "learning_rate": 0.0044466666666666665,
      "loss": 0.0071,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.012704883702099323,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.012704883702099323,
      "step": 3000
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.0005167652852833271,
      "learning_rate": 0.004224444444444445,
      "loss": 0.0071,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 0.01267404854297638,
      "step": 3100
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.0006898100255057216,
      "learning_rate": 0.004002222222222222,
      "loss": 0.0071,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 0.012587878853082657,
      "step": 3200
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.0005256439908407629,
      "learning_rate": 0.00378,
      "loss": 0.0071,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 0.012613354250788689,
      "step": 3300
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.0006175213493406773,
      "learning_rate": 0.003557777777777778,
      "loss": 0.0071,
      "step": 3400
    },
    {
      "epoch": 6.8,
      "eval_loss": 0.012556936591863632,
      "step": 3400
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.0005428273580037057,
      "learning_rate": 0.0033355555555555556,
      "loss": 0.0071,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.012512952089309692,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.012512952089309692,
      "step": 3500
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.0005162925808690488,
      "learning_rate": 0.0031133333333333334,
      "loss": 0.0071,
      "step": 3600
    },
    {
      "epoch": 7.2,
      "eval_loss": 0.012574737891554832,
      "step": 3600
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.0005161797744221985,
      "learning_rate": 0.0028911111111111112,
      "loss": 0.0071,
      "step": 3700
    },
    {
      "epoch": 7.4,
      "eval_loss": 0.01245383732020855,
      "step": 3700
    }
  ],
  "logging_steps": 100,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 100,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.001
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": true,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 20000,
  "trial_name": null,
  "trial_params": null
}
