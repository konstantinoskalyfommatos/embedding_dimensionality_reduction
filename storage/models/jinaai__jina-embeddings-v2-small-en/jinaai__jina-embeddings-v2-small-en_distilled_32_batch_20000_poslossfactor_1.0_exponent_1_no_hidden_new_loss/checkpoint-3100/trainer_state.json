{
  "best_global_step": 2900,
  "best_metric": 0.12587758898735046,
  "best_model_checkpoint": "/home/kotsios/dsit/thesis/thesis_project/storage/models/jinaai__jina-embeddings-v2-small-en/jinaai__jina-embeddings-v2-small-en_distilled_32_batch_20000_poslossfactor_1.0_exponent_1_no_hidden_new_loss/checkpoint-2900",
  "epoch": 6.2,
  "eval_steps": 100,
  "global_step": 3100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2,
      "grad_norm": 0.08203325420618057,
      "learning_rate": 0.00198,
      "loss": 1.8853,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.592150092124939,
      "step": 100
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.016169317066669464,
      "learning_rate": 0.00398,
      "loss": 0.115,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.24741394817829132,
      "step": 200
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.006876918487250805,
      "learning_rate": 0.00598,
      "loss": 0.0535,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 0.16241398453712463,
      "step": 300
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.004129026550799608,
      "learning_rate": 0.007980000000000001,
      "loss": 0.0396,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.1377461850643158,
      "step": 400
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.0032197637483477592,
      "learning_rate": 0.009980000000000001,
      "loss": 0.0348,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.13129445910453796,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.13129445910453796,
      "step": 500
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.002791487844660878,
      "learning_rate": 0.00978,
      "loss": 0.0333,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 0.13198328018188477,
      "step": 600
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.0029121371917426586,
      "learning_rate": 0.009557777777777778,
      "loss": 0.0325,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 0.13082529604434967,
      "step": 700
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.002714762231335044,
      "learning_rate": 0.009335555555555555,
      "loss": 0.0319,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 0.13237348198890686,
      "step": 800
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.002657875884324312,
      "learning_rate": 0.009113333333333333,
      "loss": 0.0314,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 0.13237546384334564,
      "step": 900
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.002483046380802989,
      "learning_rate": 0.008891111111111112,
      "loss": 0.031,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.13135164976119995,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.13135164976119995,
      "step": 1000
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.00273920688778162,
      "learning_rate": 0.00866888888888889,
      "loss": 0.0307,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 0.13142256438732147,
      "step": 1100
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.002496520057320595,
      "learning_rate": 0.008446666666666667,
      "loss": 0.0305,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 0.13129518926143646,
      "step": 1200
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.00247291661798954,
      "learning_rate": 0.008224444444444444,
      "loss": 0.0302,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 0.13110530376434326,
      "step": 1300
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.0028474668506532907,
      "learning_rate": 0.008002222222222221,
      "loss": 0.03,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 0.1306276172399521,
      "step": 1400
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.0025847163051366806,
      "learning_rate": 0.0077800000000000005,
      "loss": 0.0299,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.12953220307826996,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.12953220307826996,
      "step": 1500
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.0022940931376069784,
      "learning_rate": 0.007557777777777778,
      "loss": 0.0297,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 0.12781819701194763,
      "step": 1600
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.0024774770718067884,
      "learning_rate": 0.007335555555555555,
      "loss": 0.0296,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 0.12895523011684418,
      "step": 1700
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.0024493520613759756,
      "learning_rate": 0.0071133333333333335,
      "loss": 0.0295,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 0.12880997359752655,
      "step": 1800
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.0025372335221618414,
      "learning_rate": 0.006891111111111112,
      "loss": 0.0294,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 0.1284479945898056,
      "step": 1900
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.0028400274459272623,
      "learning_rate": 0.006668888888888889,
      "loss": 0.0293,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.12854228913784027,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.12854228913784027,
      "step": 2000
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.002507519442588091,
      "learning_rate": 0.006446666666666667,
      "loss": 0.0292,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 0.12812292575836182,
      "step": 2100
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.0025411867536604404,
      "learning_rate": 0.006224444444444445,
      "loss": 0.0291,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 0.1273152083158493,
      "step": 2200
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.0023191359359771013,
      "learning_rate": 0.006002222222222222,
      "loss": 0.029,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 0.12655125558376312,
      "step": 2300
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.0024331086315214634,
      "learning_rate": 0.0057799999999999995,
      "loss": 0.029,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 0.12734070420265198,
      "step": 2400
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.0023341954220086336,
      "learning_rate": 0.005557777777777779,
      "loss": 0.0289,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.12789493799209595,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.12789493799209595,
      "step": 2500
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.002558058360591531,
      "learning_rate": 0.005335555555555556,
      "loss": 0.0289,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 0.12800131738185883,
      "step": 2600
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.0022674468345940113,
      "learning_rate": 0.0051133333333333334,
      "loss": 0.0288,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 0.12678611278533936,
      "step": 2700
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.002366297645494342,
      "learning_rate": 0.004891111111111111,
      "loss": 0.0288,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 0.1264139860868454,
      "step": 2800
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.002276067854836583,
      "learning_rate": 0.004668888888888889,
      "loss": 0.0287,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 0.12587758898735046,
      "step": 2900
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.002482875483110547,
      "learning_rate": 0.0044466666666666665,
      "loss": 0.0287,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.12608946859836578,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.12608946859836578,
      "step": 3000
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.0025091515854001045,
      "learning_rate": 0.004224444444444445,
      "loss": 0.0286,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 0.1270449161529541,
      "step": 3100
    }
  ],
  "logging_steps": 100,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 100,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.001
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": true,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 20000,
  "trial_name": null,
  "trial_params": null
}
