{
  "best_global_step": 3500,
  "best_metric": 0.0005908851162530482,
  "best_model_checkpoint": "/home/kotsios/dsit/thesis/thesis_project/storage/models/jinaai__jina-embeddings-v2-small-en/jinaai__jina-embeddings-v2-small-en_distilled_64_batch_20000_poslossfactor_1.0_exponent_10_no_hidden/checkpoint-3500",
  "epoch": 9.2,
  "eval_steps": 100,
  "global_step": 4600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2,
      "grad_norm": 0.2507622241973877,
      "learning_rate": 0.00198,
      "loss": 2.9024,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.0017476296052336693,
      "step": 100
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.035496991127729416,
      "learning_rate": 0.00398,
      "loss": 0.0781,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.0012156390585005283,
      "step": 200
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.0451093353331089,
      "learning_rate": 0.00598,
      "loss": 0.0418,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 0.0008838981157168746,
      "step": 300
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.01689630001783371,
      "learning_rate": 0.007980000000000001,
      "loss": 0.0259,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.0007745049661025405,
      "step": 400
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.012540299445390701,
      "learning_rate": 0.009980000000000001,
      "loss": 0.0273,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.000731623382307589,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.000731623382307589,
      "step": 500
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.02131803333759308,
      "learning_rate": 0.00978,
      "loss": 0.0241,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 0.000718966533895582,
      "step": 600
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.011729379184544086,
      "learning_rate": 0.009557777777777778,
      "loss": 0.0222,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 0.0008106492459774017,
      "step": 700
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.006134317256510258,
      "learning_rate": 0.009335555555555555,
      "loss": 0.0231,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 0.0007147911819629371,
      "step": 800
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.014792945235967636,
      "learning_rate": 0.009113333333333333,
      "loss": 0.0183,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 0.0007488378323614597,
      "step": 900
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.0012816839152947068,
      "learning_rate": 0.008891111111111112,
      "loss": 0.0236,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0007745646871626377,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0007745646871626377,
      "step": 1000
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.014702189713716507,
      "learning_rate": 0.00866888888888889,
      "loss": 0.022,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 0.0007946657715365291,
      "step": 1100
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.05050697550177574,
      "learning_rate": 0.008446666666666667,
      "loss": 0.02,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 0.0006733830086886883,
      "step": 1200
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.003587663173675537,
      "learning_rate": 0.008224444444444444,
      "loss": 0.0208,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 0.000667502055875957,
      "step": 1300
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.011185571551322937,
      "learning_rate": 0.008002222222222221,
      "loss": 0.0198,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 0.0006600181222893298,
      "step": 1400
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.01629915088415146,
      "learning_rate": 0.0077800000000000005,
      "loss": 0.024,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.0006518303416669369,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.0006518303416669369,
      "step": 1500
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.015507941134274006,
      "learning_rate": 0.007557777777777778,
      "loss": 0.0216,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 0.0007018417818471789,
      "step": 1600
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.02827746421098709,
      "learning_rate": 0.007335555555555555,
      "loss": 0.0215,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 0.0007734778337180614,
      "step": 1700
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.03390355035662651,
      "learning_rate": 0.0071133333333333335,
      "loss": 0.0248,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 0.0008025202550925314,
      "step": 1800
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.027306286618113518,
      "learning_rate": 0.006891111111111112,
      "loss": 0.0206,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 0.000742878473829478,
      "step": 1900
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.018489357084035873,
      "learning_rate": 0.006668888888888889,
      "loss": 0.0205,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.0007161881076171994,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.0007161881076171994,
      "step": 2000
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.01287642028182745,
      "learning_rate": 0.006446666666666667,
      "loss": 0.0192,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 0.0007075287285260856,
      "step": 2100
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.009965365752577782,
      "learning_rate": 0.006224444444444445,
      "loss": 0.0244,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 0.0007417551823891699,
      "step": 2200
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.0012795153306797147,
      "learning_rate": 0.006002222222222222,
      "loss": 0.0213,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 0.0007223794236779213,
      "step": 2300
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.010354050435125828,
      "learning_rate": 0.0057799999999999995,
      "loss": 0.0212,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 0.0006416692631319165,
      "step": 2400
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.020612701773643494,
      "learning_rate": 0.005557777777777779,
      "loss": 0.0214,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.0006593994330614805,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.0006593994330614805,
      "step": 2500
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.033662453293800354,
      "learning_rate": 0.005335555555555556,
      "loss": 0.022,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 0.0007232092320919037,
      "step": 2600
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.05297904461622238,
      "learning_rate": 0.0051133333333333334,
      "loss": 0.0221,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 0.0007228768663480878,
      "step": 2700
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.012715527787804604,
      "learning_rate": 0.004891111111111111,
      "loss": 0.0204,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 0.0006164687220007181,
      "step": 2800
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.0430099181830883,
      "learning_rate": 0.004668888888888889,
      "loss": 0.0218,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 0.0006405228050425649,
      "step": 2900
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.02324622869491577,
      "learning_rate": 0.0044466666666666665,
      "loss": 0.0216,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.0006528269732370973,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.0006528269732370973,
      "step": 3000
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.014633108861744404,
      "learning_rate": 0.004224444444444445,
      "loss": 0.0208,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 0.0007591635221615434,
      "step": 3100
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.008787308819591999,
      "learning_rate": 0.004002222222222222,
      "loss": 0.0204,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 0.0007793102413415909,
      "step": 3200
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.01926923543214798,
      "learning_rate": 0.00378,
      "loss": 0.0218,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 0.000800020934548229,
      "step": 3300
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.06867282092571259,
      "learning_rate": 0.003557777777777778,
      "loss": 0.0203,
      "step": 3400
    },
    {
      "epoch": 6.8,
      "eval_loss": 0.000643440755084157,
      "step": 3400
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.025760231539607048,
      "learning_rate": 0.0033355555555555556,
      "loss": 0.0206,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.0005908851162530482,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.0005908851162530482,
      "step": 3500
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.018564525991678238,
      "learning_rate": 0.0031133333333333334,
      "loss": 0.0239,
      "step": 3600
    },
    {
      "epoch": 7.2,
      "eval_loss": 0.0007036433089524508,
      "step": 3600
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.045383088290691376,
      "learning_rate": 0.0028911111111111112,
      "loss": 0.0192,
      "step": 3700
    },
    {
      "epoch": 7.4,
      "eval_loss": 0.0006345369620248675,
      "step": 3700
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.019940538331866264,
      "learning_rate": 0.002668888888888889,
      "loss": 0.0202,
      "step": 3800
    },
    {
      "epoch": 7.6,
      "eval_loss": 0.0006948407972231507,
      "step": 3800
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.021268483251333237,
      "learning_rate": 0.002446666666666667,
      "loss": 0.0219,
      "step": 3900
    },
    {
      "epoch": 7.8,
      "eval_loss": 0.0006240943912416697,
      "step": 3900
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.020823189988732338,
      "learning_rate": 0.0022244444444444447,
      "loss": 0.0205,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.0007128068245947361,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.0007128068245947361,
      "step": 4000
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.03557509183883667,
      "learning_rate": 0.002002222222222222,
      "loss": 0.0194,
      "step": 4100
    },
    {
      "epoch": 8.2,
      "eval_loss": 0.0007081402000039816,
      "step": 4100
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.00774071179330349,
      "learning_rate": 0.00178,
      "loss": 0.0181,
      "step": 4200
    },
    {
      "epoch": 8.4,
      "eval_loss": 0.0007071942673064768,
      "step": 4200
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.0012681334046646953,
      "learning_rate": 0.0015577777777777777,
      "loss": 0.0208,
      "step": 4300
    },
    {
      "epoch": 8.6,
      "eval_loss": 0.0006990435067564249,
      "step": 4300
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.014124157838523388,
      "learning_rate": 0.0013355555555555558,
      "loss": 0.0208,
      "step": 4400
    },
    {
      "epoch": 8.8,
      "eval_loss": 0.0007565068663097918,
      "step": 4400
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.005451474338769913,
      "learning_rate": 0.0011133333333333334,
      "loss": 0.0187,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.0007457308238372207,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.0007457308238372207,
      "step": 4500
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.0076386467553675175,
      "learning_rate": 0.0008911111111111112,
      "loss": 0.0173,
      "step": 4600
    },
    {
      "epoch": 9.2,
      "eval_loss": 0.0007189633324742317,
      "step": 4600
    }
  ],
  "logging_steps": 100,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 100,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.001
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": true,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 20000,
  "trial_name": null,
  "trial_params": null
}
