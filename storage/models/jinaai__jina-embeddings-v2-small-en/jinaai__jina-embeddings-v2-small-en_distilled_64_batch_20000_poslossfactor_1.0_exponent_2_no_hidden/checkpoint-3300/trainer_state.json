{
  "best_global_step": 3200,
  "best_metric": 5.340584721125197e-06,
  "best_model_checkpoint": "/home/kotsios/dsit/thesis/thesis_project/storage/models/jinaai__jina-embeddings-v2-small-en/jinaai__jina-embeddings-v2-small-en_distilled_64_batch_20000_poslossfactor_1.0_exponent_2_no_hidden/checkpoint-3200",
  "epoch": 6.6,
  "eval_steps": 100,
  "global_step": 3300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2,
      "grad_norm": 0.14278873801231384,
      "learning_rate": 0.00198,
      "loss": 6.3142,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 2.136233524652198e-05,
      "step": 100
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.019147371873259544,
      "learning_rate": 0.00398,
      "loss": 0.1346,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 1.220704143634066e-05,
      "step": 200
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.00994779635220766,
      "learning_rate": 0.00598,
      "loss": 0.0667,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 7.629402716702316e-06,
      "step": 300
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.007921098731458187,
      "learning_rate": 0.007980000000000001,
      "loss": 0.0523,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 1.5258796338457614e-05,
      "step": 400
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.00719253346323967,
      "learning_rate": 0.009980000000000001,
      "loss": 0.048,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.2969979252375197e-05,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.2969979252375197e-05,
      "step": 500
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.00769196217879653,
      "learning_rate": 0.00978,
      "loss": 0.0458,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 1.2969978342880495e-05,
      "step": 600
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.006787342019379139,
      "learning_rate": 0.009557777777777778,
      "loss": 0.0444,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 1.9073493604082614e-05,
      "step": 700
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.006781614851206541,
      "learning_rate": 0.009335555555555555,
      "loss": 0.0435,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 3.128052776446566e-05,
      "step": 800
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.006449942477047443,
      "learning_rate": 0.009113333333333333,
      "loss": 0.0428,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 1.5258798157447018e-05,
      "step": 900
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.006605289876461029,
      "learning_rate": 0.008891111111111112,
      "loss": 0.0424,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.6784675608505495e-05,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.6784675608505495e-05,
      "step": 1000
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.006316241808235645,
      "learning_rate": 0.00866888888888889,
      "loss": 0.042,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 1.4495857612928376e-05,
      "step": 1100
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.007051203399896622,
      "learning_rate": 0.008446666666666667,
      "loss": 0.0417,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 1.2969978342880495e-05,
      "step": 1200
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.0065496256574988365,
      "learning_rate": 0.008224444444444444,
      "loss": 0.0411,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 2.2888190869707614e-05,
      "step": 1300
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.0071840714663267136,
      "learning_rate": 0.008002222222222221,
      "loss": 0.0409,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 1.6021736882976256e-05,
      "step": 1400
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.006662190426141024,
      "learning_rate": 0.0077800000000000005,
      "loss": 0.0412,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.6784675608505495e-05,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.6784675608505495e-05,
      "step": 1500
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.006457932759076357,
      "learning_rate": 0.007557777777777778,
      "loss": 0.041,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 1.2969978342880495e-05,
      "step": 1600
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.009190654382109642,
      "learning_rate": 0.007335555555555555,
      "loss": 0.0408,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 1.9073493604082614e-05,
      "step": 1700
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.007489058654755354,
      "learning_rate": 0.0071133333333333335,
      "loss": 0.0408,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 1.3732918887399137e-05,
      "step": 1800
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.006474992260336876,
      "learning_rate": 0.006891111111111112,
      "loss": 0.0407,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 1.5258796338457614e-05,
      "step": 1900
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.006349614821374416,
      "learning_rate": 0.006668888888888889,
      "loss": 0.0407,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.0599372874130495e-05,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.0599372874130495e-05,
      "step": 2000
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.006754687521606684,
      "learning_rate": 0.006446666666666667,
      "loss": 0.0405,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 7.629402716702316e-06,
      "step": 2100
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.006608733907341957,
      "learning_rate": 0.006224444444444445,
      "loss": 0.0405,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 1.602173870196566e-05,
      "step": 2200
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.0062175472266972065,
      "learning_rate": 0.006002222222222222,
      "loss": 0.0405,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 9.918220712279435e-06,
      "step": 2300
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.007155002560466528,
      "learning_rate": 0.0057799999999999995,
      "loss": 0.0404,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 1.4495857612928376e-05,
      "step": 2400
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.0067892675288021564,
      "learning_rate": 0.005557777777777779,
      "loss": 0.0399,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 2.5939949409803376e-05,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 2.5939949409803376e-05,
      "step": 2500
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.006366020999848843,
      "learning_rate": 0.005335555555555556,
      "loss": 0.0402,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 1.67846774274949e-05,
      "step": 2600
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.006706726737320423,
      "learning_rate": 0.0051133333333333334,
      "loss": 0.0399,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 2.2888190869707614e-05,
      "step": 2700
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.006166248582303524,
      "learning_rate": 0.004891111111111111,
      "loss": 0.0402,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 1.1444100891822018e-05,
      "step": 2800
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.0075353519059717655,
      "learning_rate": 0.004668888888888889,
      "loss": 0.0402,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 1.5258796338457614e-05,
      "step": 2900
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.006556489504873753,
      "learning_rate": 0.0044466666666666665,
      "loss": 0.0401,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.6021735063986853e-05,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.6021735063986853e-05,
      "step": 3000
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.006267833989113569,
      "learning_rate": 0.004224444444444445,
      "loss": 0.0397,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 1.67846774274949e-05,
      "step": 3100
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.007554816547781229,
      "learning_rate": 0.004002222222222222,
      "loss": 0.0401,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 5.340584721125197e-06,
      "step": 3200
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.006764312274754047,
      "learning_rate": 0.00378,
      "loss": 0.0401,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 1.7547614334034733e-05,
      "step": 3300
    }
  ],
  "logging_steps": 100,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 100,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.001
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": true,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 20000,
  "trial_name": null,
  "trial_params": null
}
