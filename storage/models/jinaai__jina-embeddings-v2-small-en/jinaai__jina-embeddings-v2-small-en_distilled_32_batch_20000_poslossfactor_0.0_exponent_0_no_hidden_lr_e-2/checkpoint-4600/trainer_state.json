{
  "best_global_step": 200,
  "best_metric": 0.4111548066139221,
  "best_model_checkpoint": "/home/kotsios/dsit/thesis/thesis_project/storage/models/jinaai__jina-embeddings-v2-small-en/jinaai__jina-embeddings-v2-small-en_distilled_32_batch_20000_poslossfactor_0.0/checkpoint-200",
  "epoch": 9.2,
  "eval_steps": 100,
  "global_step": 4600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2,
      "grad_norm": 14.170340538024902,
      "learning_rate": 0.00198,
      "loss": 0.5143,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.5421779751777649,
      "step": 100
    },
    {
      "epoch": 0.4,
      "grad_norm": 6.65880012512207,
      "learning_rate": 0.00398,
      "loss": 0.4425,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.4111548066139221,
      "step": 200
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0733486413955688,
      "learning_rate": 0.00598,
      "loss": 0.2895,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 1.430827260017395,
      "step": 300
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5337674617767334,
      "learning_rate": 0.007980000000000001,
      "loss": 0.4735,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.6235162019729614,
      "step": 400
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.9790191650390625,
      "learning_rate": 0.009980000000000001,
      "loss": 0.3391,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.1724709272384644,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.1724709272384644,
      "step": 500
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.09524402022361755,
      "learning_rate": 0.00978,
      "loss": 0.2768,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 0.5806785821914673,
      "step": 600
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.23327068984508514,
      "learning_rate": 0.009557777777777778,
      "loss": 0.2514,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 0.622893750667572,
      "step": 700
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.3493516743183136,
      "learning_rate": 0.009335555555555555,
      "loss": 0.2502,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 0.6182997822761536,
      "step": 800
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.5722550749778748,
      "learning_rate": 0.009113333333333333,
      "loss": 0.2494,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 0.6394119262695312,
      "step": 900
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.08730676770210266,
      "learning_rate": 0.008891111111111112,
      "loss": 0.2473,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.5821844935417175,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.5821844935417175,
      "step": 1000
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.13873445987701416,
      "learning_rate": 0.00866888888888889,
      "loss": 0.2464,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 0.595449686050415,
      "step": 1100
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.6869061589241028,
      "learning_rate": 0.008446666666666667,
      "loss": 0.2433,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 0.5218084454536438,
      "step": 1200
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.028041725978255272,
      "learning_rate": 0.008224444444444444,
      "loss": 0.2434,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 0.5928400158882141,
      "step": 1300
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.053777143359184265,
      "learning_rate": 0.008002222222222221,
      "loss": 0.2417,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 0.5739893317222595,
      "step": 1400
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.3362423777580261,
      "learning_rate": 0.0077800000000000005,
      "loss": 0.2405,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.5384612083435059,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.5384612083435059,
      "step": 1500
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.05905589461326599,
      "learning_rate": 0.007557777777777778,
      "loss": 0.2414,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 0.5720653533935547,
      "step": 1600
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.10703461617231369,
      "learning_rate": 0.007335555555555555,
      "loss": 0.2391,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 0.5372321605682373,
      "step": 1700
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.6712178587913513,
      "learning_rate": 0.0071133333333333335,
      "loss": 0.239,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 0.6169365048408508,
      "step": 1800
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.1428658813238144,
      "learning_rate": 0.006891111111111112,
      "loss": 0.2285,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 0.5345408320426941,
      "step": 1900
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.2288530468940735,
      "learning_rate": 0.006668888888888889,
      "loss": 0.2262,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.5757625102996826,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.5757625102996826,
      "step": 2000
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.05624569579958916,
      "learning_rate": 0.006446666666666667,
      "loss": 0.2285,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 0.5813448429107666,
      "step": 2100
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.11650832742452621,
      "learning_rate": 0.006224444444444445,
      "loss": 0.2196,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 0.5267478823661804,
      "step": 2200
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.0899602472782135,
      "learning_rate": 0.006002222222222222,
      "loss": 0.215,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 0.5132612586021423,
      "step": 2300
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.1181342601776123,
      "learning_rate": 0.0057799999999999995,
      "loss": 0.215,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 0.514819324016571,
      "step": 2400
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.15665081143379211,
      "learning_rate": 0.005557777777777779,
      "loss": 0.2149,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.5138336420059204,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.5138336420059204,
      "step": 2500
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.02271963469684124,
      "learning_rate": 0.005335555555555556,
      "loss": 0.214,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 0.5151702761650085,
      "step": 2600
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.14043253660202026,
      "learning_rate": 0.0051133333333333334,
      "loss": 0.2135,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 0.5328707695007324,
      "step": 2700
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.10986243188381195,
      "learning_rate": 0.004891111111111111,
      "loss": 0.2138,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 0.523080587387085,
      "step": 2800
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.3640994727611542,
      "learning_rate": 0.004668888888888889,
      "loss": 0.2131,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 0.4921257495880127,
      "step": 2900
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.11984123289585114,
      "learning_rate": 0.0044466666666666665,
      "loss": 0.2151,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.5189834237098694,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.5189834237098694,
      "step": 3000
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.055387452244758606,
      "learning_rate": 0.004224444444444445,
      "loss": 0.2127,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 0.5122154951095581,
      "step": 3100
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.12746629118919373,
      "learning_rate": 0.004002222222222222,
      "loss": 0.2122,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 0.5047850608825684,
      "step": 3200
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.15397042036056519,
      "learning_rate": 0.00378,
      "loss": 0.2124,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 0.5245178937911987,
      "step": 3300
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.06360973417758942,
      "learning_rate": 0.003557777777777778,
      "loss": 0.2124,
      "step": 3400
    },
    {
      "epoch": 6.8,
      "eval_loss": 0.4969269037246704,
      "step": 3400
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.021277153864502907,
      "learning_rate": 0.0033355555555555556,
      "loss": 0.2116,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.5079044699668884,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.5079044699668884,
      "step": 3500
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.03753974288702011,
      "learning_rate": 0.0031133333333333334,
      "loss": 0.2114,
      "step": 3600
    },
    {
      "epoch": 7.2,
      "eval_loss": 0.5086539387702942,
      "step": 3600
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.027220025658607483,
      "learning_rate": 0.0028911111111111112,
      "loss": 0.2118,
      "step": 3700
    },
    {
      "epoch": 7.4,
      "eval_loss": 0.4954460859298706,
      "step": 3700
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.022725379094481468,
      "learning_rate": 0.002668888888888889,
      "loss": 0.2113,
      "step": 3800
    },
    {
      "epoch": 7.6,
      "eval_loss": 0.5183190107345581,
      "step": 3800
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.13813410699367523,
      "learning_rate": 0.002446666666666667,
      "loss": 0.2113,
      "step": 3900
    },
    {
      "epoch": 7.8,
      "eval_loss": 0.4974803924560547,
      "step": 3900
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.08626613765954971,
      "learning_rate": 0.0022244444444444447,
      "loss": 0.2109,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.5041694045066833,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.5041694045066833,
      "step": 4000
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.04381513595581055,
      "learning_rate": 0.002002222222222222,
      "loss": 0.2109,
      "step": 4100
    },
    {
      "epoch": 8.2,
      "eval_loss": 0.511145293712616,
      "step": 4100
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.07150610536336899,
      "learning_rate": 0.00178,
      "loss": 0.2107,
      "step": 4200
    },
    {
      "epoch": 8.4,
      "eval_loss": 0.5139985680580139,
      "step": 4200
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.05547124519944191,
      "learning_rate": 0.0015577777777777777,
      "loss": 0.2107,
      "step": 4300
    },
    {
      "epoch": 8.6,
      "eval_loss": 0.5040761828422546,
      "step": 4300
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.06740438938140869,
      "learning_rate": 0.0013355555555555558,
      "loss": 0.2106,
      "step": 4400
    },
    {
      "epoch": 8.8,
      "eval_loss": 0.5105693936347961,
      "step": 4400
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.019329579547047615,
      "learning_rate": 0.0011133333333333334,
      "loss": 0.2104,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.5092485547065735,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.5092485547065735,
      "step": 4500
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.031002512201666832,
      "learning_rate": 0.0008911111111111112,
      "loss": 0.2103,
      "step": 4600
    },
    {
      "epoch": 9.2,
      "eval_loss": 0.4959387183189392,
      "step": 4600
    }
  ],
  "logging_steps": 100,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 100,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.001
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": true,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 20000,
  "trial_name": null,
  "trial_params": null
}
