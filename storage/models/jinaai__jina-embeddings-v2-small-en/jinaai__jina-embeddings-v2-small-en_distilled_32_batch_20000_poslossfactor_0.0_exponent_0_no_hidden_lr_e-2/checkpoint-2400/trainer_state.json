{
  "best_global_step": 200,
  "best_metric": 0.4111548066139221,
  "best_model_checkpoint": "/home/kotsios/dsit/thesis/thesis_project/storage/models/jinaai__jina-embeddings-v2-small-en/jinaai__jina-embeddings-v2-small-en_distilled_32_batch_20000_poslossfactor_0.0/checkpoint-200",
  "epoch": 4.8,
  "eval_steps": 100,
  "global_step": 2400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2,
      "grad_norm": 14.170340538024902,
      "learning_rate": 0.00198,
      "loss": 0.5143,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.5421779751777649,
      "step": 100
    },
    {
      "epoch": 0.4,
      "grad_norm": 6.65880012512207,
      "learning_rate": 0.00398,
      "loss": 0.4425,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.4111548066139221,
      "step": 200
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0733486413955688,
      "learning_rate": 0.00598,
      "loss": 0.2895,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 1.430827260017395,
      "step": 300
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5337674617767334,
      "learning_rate": 0.007980000000000001,
      "loss": 0.4735,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.6235162019729614,
      "step": 400
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.9790191650390625,
      "learning_rate": 0.009980000000000001,
      "loss": 0.3391,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.1724709272384644,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.1724709272384644,
      "step": 500
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.09524402022361755,
      "learning_rate": 0.00978,
      "loss": 0.2768,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 0.5806785821914673,
      "step": 600
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.23327068984508514,
      "learning_rate": 0.009557777777777778,
      "loss": 0.2514,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 0.622893750667572,
      "step": 700
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.3493516743183136,
      "learning_rate": 0.009335555555555555,
      "loss": 0.2502,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 0.6182997822761536,
      "step": 800
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.5722550749778748,
      "learning_rate": 0.009113333333333333,
      "loss": 0.2494,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 0.6394119262695312,
      "step": 900
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.08730676770210266,
      "learning_rate": 0.008891111111111112,
      "loss": 0.2473,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.5821844935417175,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.5821844935417175,
      "step": 1000
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.13873445987701416,
      "learning_rate": 0.00866888888888889,
      "loss": 0.2464,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 0.595449686050415,
      "step": 1100
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.6869061589241028,
      "learning_rate": 0.008446666666666667,
      "loss": 0.2433,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 0.5218084454536438,
      "step": 1200
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.028041725978255272,
      "learning_rate": 0.008224444444444444,
      "loss": 0.2434,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 0.5928400158882141,
      "step": 1300
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.053777143359184265,
      "learning_rate": 0.008002222222222221,
      "loss": 0.2417,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 0.5739893317222595,
      "step": 1400
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.3362423777580261,
      "learning_rate": 0.0077800000000000005,
      "loss": 0.2405,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.5384612083435059,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.5384612083435059,
      "step": 1500
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.05905589461326599,
      "learning_rate": 0.007557777777777778,
      "loss": 0.2414,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 0.5720653533935547,
      "step": 1600
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.10703461617231369,
      "learning_rate": 0.007335555555555555,
      "loss": 0.2391,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 0.5372321605682373,
      "step": 1700
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.6712178587913513,
      "learning_rate": 0.0071133333333333335,
      "loss": 0.239,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 0.6169365048408508,
      "step": 1800
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.1428658813238144,
      "learning_rate": 0.006891111111111112,
      "loss": 0.2285,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 0.5345408320426941,
      "step": 1900
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.2288530468940735,
      "learning_rate": 0.006668888888888889,
      "loss": 0.2262,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.5757625102996826,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.5757625102996826,
      "step": 2000
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.05624569579958916,
      "learning_rate": 0.006446666666666667,
      "loss": 0.2285,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 0.5813448429107666,
      "step": 2100
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.11650832742452621,
      "learning_rate": 0.006224444444444445,
      "loss": 0.2196,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 0.5267478823661804,
      "step": 2200
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.0899602472782135,
      "learning_rate": 0.006002222222222222,
      "loss": 0.215,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 0.5132612586021423,
      "step": 2300
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.1181342601776123,
      "learning_rate": 0.0057799999999999995,
      "loss": 0.215,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 0.514819324016571,
      "step": 2400
    }
  ],
  "logging_steps": 100,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 100,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.001
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": true,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 20000,
  "trial_name": null,
  "trial_params": null
}
