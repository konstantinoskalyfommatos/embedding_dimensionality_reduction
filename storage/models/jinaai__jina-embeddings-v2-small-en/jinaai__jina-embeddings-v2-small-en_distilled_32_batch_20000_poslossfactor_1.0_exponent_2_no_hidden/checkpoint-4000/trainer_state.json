{
  "best_global_step": 3400,
  "best_metric": 2.288834821229102e-06,
  "best_model_checkpoint": "/home/kotsios/dsit/thesis/thesis_project/storage/models/jinaai__jina-embeddings-v2-small-en/jinaai__jina-embeddings-v2-small-en_distilled_32_batch_20000_poslossfactor_1.0_exponent_2_no_hidden/checkpoint-3400",
  "epoch": 8.0,
  "eval_steps": 100,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2,
      "grad_norm": 0.2280161827802658,
      "learning_rate": 0.00198,
      "loss": 8.2909,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 1.14441427285783e-05,
      "step": 100
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.03120306320488453,
      "learning_rate": 0.00398,
      "loss": 0.2978,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 1.0299703717464581e-05,
      "step": 200
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.014200873672962189,
      "learning_rate": 0.00598,
      "loss": 0.1712,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 9.536761353956535e-06,
      "step": 300
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.012606930918991566,
      "learning_rate": 0.007980000000000001,
      "loss": 0.1531,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 8.773819899943192e-06,
      "step": 400
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.01278688944876194,
      "learning_rate": 0.009980000000000001,
      "loss": 0.1472,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.2207047802803572e-05,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.2207047802803572e-05,
      "step": 500
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.01168937049806118,
      "learning_rate": 0.00978,
      "loss": 0.143,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 1.1444108167779632e-05,
      "step": 600
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.013926733285188675,
      "learning_rate": 0.009557777777777778,
      "loss": 0.1402,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 4.196183908788953e-06,
      "step": 700
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.0129427220672369,
      "learning_rate": 0.009335555555555555,
      "loss": 0.1382,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 1.1825577530544251e-05,
      "step": 800
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.012248787097632885,
      "learning_rate": 0.009113333333333333,
      "loss": 0.1368,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 9.918228897731751e-06,
      "step": 900
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.01102512702345848,
      "learning_rate": 0.008891111111111112,
      "loss": 0.1356,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 5.722062269342132e-06,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 5.722062269342132e-06,
      "step": 1000
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.013478769920766354,
      "learning_rate": 0.00866888888888889,
      "loss": 0.1348,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 6.103532086854102e-06,
      "step": 1100
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.012813699431717396,
      "learning_rate": 0.008446666666666667,
      "loss": 0.1341,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 8.010880264919251e-06,
      "step": 1200
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.01344886515289545,
      "learning_rate": 0.008224444444444444,
      "loss": 0.1321,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 1.220704689330887e-05,
      "step": 1300
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.012267917394638062,
      "learning_rate": 0.008002222222222221,
      "loss": 0.1317,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 1.2588518075062893e-05,
      "step": 1400
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.010531624779105186,
      "learning_rate": 0.0077800000000000005,
      "loss": 0.1327,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 8.010880264919251e-06,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 8.010880264919251e-06,
      "step": 1500
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.0112489378079772,
      "learning_rate": 0.007557777777777778,
      "loss": 0.1322,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 6.103532086854102e-06,
      "step": 1600
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.01483118161559105,
      "learning_rate": 0.007335555555555555,
      "loss": 0.1319,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 9.155289262707811e-06,
      "step": 1700
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.01160088274627924,
      "learning_rate": 0.0071133333333333335,
      "loss": 0.1316,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 8.010880264919251e-06,
      "step": 1800
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.01052719634026289,
      "learning_rate": 0.006891111111111112,
      "loss": 0.1314,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 1.564027479616925e-05,
      "step": 1900
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.01313786581158638,
      "learning_rate": 0.006668888888888889,
      "loss": 0.1312,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.0980851331842132e-05,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.0980851331842132e-05,
      "step": 2000
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.010836968198418617,
      "learning_rate": 0.006446666666666667,
      "loss": 0.1309,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 9.918228897731751e-06,
      "step": 2100
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.012017468921840191,
      "learning_rate": 0.006224444444444445,
      "loss": 0.1307,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 1.1825577530544251e-05,
      "step": 2200
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.010991797782480717,
      "learning_rate": 0.006002222222222222,
      "loss": 0.1306,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 3.814713636529632e-06,
      "step": 2300
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.01051807589828968,
      "learning_rate": 0.0057799999999999995,
      "loss": 0.1304,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 8.39234962768387e-06,
      "step": 2400
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.012500058859586716,
      "learning_rate": 0.005557777777777779,
      "loss": 0.1289,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.0681168532755692e-05,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.0681168532755692e-05,
      "step": 2500
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.011648990213871002,
      "learning_rate": 0.005335555555555556,
      "loss": 0.13,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 9.53675862547243e-06,
      "step": 2600
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.0134156234562397,
      "learning_rate": 0.0051133333333333334,
      "loss": 0.1286,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 6.103532086854102e-06,
      "step": 2700
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.011843410320580006,
      "learning_rate": 0.004891111111111111,
      "loss": 0.1298,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 1.220704689330887e-05,
      "step": 2800
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.011089727282524109,
      "learning_rate": 0.004668888888888889,
      "loss": 0.1297,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 1.068116762326099e-05,
      "step": 2900
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.011555199511349201,
      "learning_rate": 0.0044466666666666665,
      "loss": 0.1295,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.0299697351001669e-05,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.0299697351001669e-05,
      "step": 3000
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.010775046423077583,
      "learning_rate": 0.004224444444444445,
      "loss": 0.1281,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 6.866470812383341e-06,
      "step": 3100
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.014044984243810177,
      "learning_rate": 0.004002222222222222,
      "loss": 0.1294,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 1.5258805433404632e-05,
      "step": 3200
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.011915338225662708,
      "learning_rate": 0.00378,
      "loss": 0.1292,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 6.103531632106751e-06,
      "step": 3300
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.011102944612503052,
      "learning_rate": 0.003557777777777778,
      "loss": 0.1279,
      "step": 3400
    },
    {
      "epoch": 6.8,
      "eval_loss": 2.288834821229102e-06,
      "step": 3400
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.011708990670740604,
      "learning_rate": 0.0033355555555555556,
      "loss": 0.1265,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 5.340591997082811e-06,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 5.340591997082811e-06,
      "step": 3500
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.010510595515370369,
      "learning_rate": 0.0031133333333333334,
      "loss": 0.129,
      "step": 3600
    },
    {
      "epoch": 7.2,
      "eval_loss": 3.814713636529632e-06,
      "step": 3600
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.010871490463614464,
      "learning_rate": 0.0028911111111111112,
      "loss": 0.1276,
      "step": 3700
    },
    {
      "epoch": 7.4,
      "eval_loss": 1.258851625607349e-05,
      "step": 3700
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.012551933526992798,
      "learning_rate": 0.002668888888888889,
      "loss": 0.1289,
      "step": 3800
    },
    {
      "epoch": 7.6,
      "eval_loss": 1.220704689330887e-05,
      "step": 3800
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.010088247247040272,
      "learning_rate": 0.002446666666666667,
      "loss": 0.1287,
      "step": 3900
    },
    {
      "epoch": 7.8,
      "eval_loss": 1.0681169442250393e-05,
      "step": 3900
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.010459516197443008,
      "learning_rate": 0.0022244444444444447,
      "loss": 0.1287,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 5.340591997082811e-06,
      "step": 4000
    }
  ],
  "logging_steps": 100,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 100,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.001
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": true,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 20000,
  "trial_name": null,
  "trial_params": null
}
